{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Files From Raw Files (Clinical data, Transcriptomic data, Methylomics data, Metabolomics data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "phenodata_df = pd.read_excel('./data/pheno_data/LLFS_phenos_21JUN2022.xlsx', sheet_name='Phenodata').sort_values(by='subject')\n",
    "# Convert the subject column to string\n",
    "phenodata_df['subject'] = phenodata_df['subject'].astype(str)\n",
    "display(phenodata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read t2ds label data\n",
    "import numpy as np\n",
    "t2ds_label_df = pd.read_table('./data/label_data/t2dpret2d.txt')\n",
    "t2ds_label_df = t2ds_label_df.replace('.', 0)\n",
    "t2ds_label_df['pret2ds'] = t2ds_label_df['pret2ds'].astype(np.int64)\n",
    "t2ds_label_df = t2ds_label_df.sort_values(by='subject')\n",
    "t2ds_label_df['subject'] = t2ds_label_df['subject'].astype(str)\n",
    "print(t2ds_label_df.dtypes)\n",
    "display(t2ds_label_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transcriptomic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_v1_df = pd.read_csv('./data/omics_data/residuals/RNA_seq_residuals_v1_allsubjects.csv').sort_values(by='subject')\n",
    "display(tran_v1_df)\n",
    "tran_v1_df_transposed = tran_v1_df.T\n",
    "# Convert the first row to strings, remove any '.0' at the end, and set it as the new header (column names)\n",
    "tran_v1_df_transposed.columns = tran_v1_df_transposed.iloc[0].astype(str).str.replace('.0', '', regex=False)\n",
    "# Drop the first row as it's now the header\n",
    "tran_v1_df_transposed = tran_v1_df_transposed.drop(tran_v1_df_transposed.index[0])\n",
    "# Reset the index\n",
    "tran_v1_df = tran_v1_df_transposed.reset_index()\n",
    "# Rename the first column to 'subject'\n",
    "tran_v1_df = tran_v1_df.rename(columns={'index': 'gene_id'})\n",
    "# Convert the version gene ID to the gene ID\n",
    "ensembl_gene_ids = tran_v1_df['gene_id'].apply(lambda x: x.split('.')[0]).tolist()\n",
    "tran_v1_df['gene_id'] = ensembl_gene_ids\n",
    "display(tran_v1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the gene ID in the ensembl_data dataframe\n",
    "ensembl_data = pd.read_csv('./data/kg_data/ensembl/mart_export_genename.txt')\n",
    "ensembl_data= ensembl_data.rename(columns={'Gene stable ID': 'gene_id'}).dropna().drop_duplicates().reset_index(drop=True)\n",
    "display(ensembl_data)\n",
    "# Convert the 'Gene Name' column to 'gene_name'\n",
    "ensembl_data = ensembl_data.rename(columns={'Gene name': 'gene_name'})\n",
    "merged_tran_v1_df = pd.merge(tran_v1_df, ensembl_data, on='gene_id', how='inner')\n",
    "# Move the gene name to the first column\n",
    "merged_tran_v1_df = merged_tran_v1_df[['gene_name'] + [col for col in merged_tran_v1_df.columns if col != 'gene_name']]\n",
    "# Drop the gene ID column\n",
    "merged_tran_v1_df = merged_tran_v1_df.drop(columns=['gene_id'])\n",
    "# Drop duplicated rows and aggregate the rows by grouping them by gene name\n",
    "merged_tran_v1_df = merged_tran_v1_df.groupby(['gene_name']).mean().reset_index()\n",
    "display(merged_tran_v1_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Methylation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_promoter_df = pd.read_csv('./data/omics_data/epigenomics/Core_Promoter_final.csv').sort_values(by='gene_name').reset_index(drop=True)\n",
    "core_promoter_sorted_df = core_promoter_df[['gene_name'] + sorted(core_promoter_df.columns[1:], key=lambda x: int(x))] # Sort the dataframe columns (excluding 'gene_name') numerically\n",
    "distal_promoter_df = pd.read_csv('./data/omics_data/epigenomics/Distal_Promoter_final.csv').sort_values(by='gene_name').reset_index(drop=True)\n",
    "distal_promoter_sorted_df = distal_promoter_df[['gene_name'] + sorted(distal_promoter_df.columns[1:], key=lambda x: int(x))] # Sort the dataframe columns (excluding 'gene_name') numerically\n",
    "downstream_df = pd.read_csv('./data/omics_data/epigenomics/Downstream_final.csv').sort_values(by='gene_name').reset_index(drop=True)\n",
    "downstream_sorted_df = downstream_df[['gene_name'] + sorted(downstream_df.columns[1:], key=lambda x: int(x))] # Sort the dataframe columns (excluding 'gene_name') numerically\n",
    "proximal_promoter_df = pd.read_csv('./data/omics_data/epigenomics/Proximal_Promoter_final.csv').sort_values(by='gene_name').reset_index(drop=True)\n",
    "proximal_promoter_sorted_df = proximal_promoter_df[['gene_name'] + sorted(proximal_promoter_df.columns[1:], key=lambda x: int(x))] # Sort the dataframe columns (excluding 'gene_name') numerically\n",
    "upstream_df = pd.read_csv('./data/omics_data/epigenomics/Upstream_final.csv').sort_values(by='gene_name').reset_index(drop=True)\n",
    "upstream_sorted_df = upstream_df[['gene_name'] + sorted(upstream_df.columns[1:], key=lambda x: int(x))] # Sort the dataframe columns (excluding 'gene_name') numerically\n",
    "display(upstream_sorted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep gene names in the ensebmle_data dataframe and drop gene_id\n",
    "merged_core_promoter_df = pd.merge(core_promoter_sorted_df, ensembl_data, on='gene_name', how='inner').drop(columns=['gene_id'])\n",
    "merged_core_promoter_df = merged_core_promoter_df.groupby(['gene_name']).mean().reset_index()\n",
    "merged_distal_promoter_df = pd.merge(distal_promoter_sorted_df, ensembl_data, on='gene_name', how='inner').drop(columns=['gene_id'])\n",
    "merged_distal_promoter_df = merged_distal_promoter_df.groupby(['gene_name']).mean().reset_index()\n",
    "merged_downstream_df = pd.merge(downstream_sorted_df, ensembl_data, on='gene_name', how='inner').drop(columns=['gene_id'])\n",
    "merged_downstream_df = merged_downstream_df.groupby(['gene_name']).mean().reset_index()\n",
    "merged_proximal_promoter_df = pd.merge(proximal_promoter_sorted_df, ensembl_data, on='gene_name', how='inner').drop(columns=['gene_id'])\n",
    "merged_proximal_promoter_df = merged_proximal_promoter_df.groupby(['gene_name']).mean().reset_index()\n",
    "merged_upstream_df = pd.merge(upstream_sorted_df, ensembl_data, on='gene_name', how='inner').drop(columns=['gene_id'])\n",
    "merged_upstream_df = merged_upstream_df.groupby(['gene_name']).mean().reset_index()\n",
    "display(merged_upstream_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gene and Sample Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Gene Intersection Over Omics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tran_v1_gene = set(merged_tran_v1_df['gene_name'].tolist())\n",
    "merged_core_promoter_gene = set(merged_core_promoter_df['gene_name'].tolist())\n",
    "intersected_gene = sorted(list(merged_tran_v1_gene & merged_core_promoter_gene))\n",
    "print(intersected_gene)\n",
    "print('intersected_gene:', len(intersected_gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the gene names that are in both the tran_v1 and core_promoter dataframes\n",
    "merged_tran_v1_df = merged_tran_v1_df[merged_tran_v1_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "merged_core_promoter_df = merged_core_promoter_df[merged_core_promoter_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "merged_distal_promoter_df = merged_distal_promoter_df[merged_distal_promoter_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "merged_downstream_df = merged_downstream_df[merged_downstream_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "merged_proximal_promoter_df = merged_proximal_promoter_df[merged_proximal_promoter_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "merged_upstream_df = merged_upstream_df[merged_upstream_df['gene_name'].isin(intersected_gene)].reset_index(drop=True)\n",
    "display(merged_tran_v1_df)\n",
    "display(merged_upstream_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Regulatory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the gene names from databases like [KEGG / BioGRID] to intersect with the common genes\n",
    "# KEGG\n",
    "kegg_pathway_df = pd.read_csv('./data/kg_data/KEGG/full_kegg_pathway_list.csv')\n",
    "kegg_pathway_df = kegg_pathway_df[['source', 'target', 'pathway_name']]\n",
    "kegg_df = kegg_pathway_df[kegg_pathway_df['pathway_name'].str.contains('signaling pathway|signaling pathways', case=False)]\n",
    "print(kegg_df['pathway_name'].value_counts())\n",
    "kegg_df = kegg_df.rename(columns={'source': 'src', 'target': 'dest'})\n",
    "src_list = list(kegg_df['src'])\n",
    "dest_list = list(kegg_df['dest'])\n",
    "path_list = list(kegg_df['pathway_name'])\n",
    "# Adjust all genes to uppercase\n",
    "up_src_list = []\n",
    "for src in src_list:\n",
    "    up_src = src.upper()\n",
    "    up_src_list.append(up_src)\n",
    "up_dest_list = []\n",
    "for dest in dest_list:\n",
    "    up_dest = dest.upper()\n",
    "    up_dest_list.append(up_dest)\n",
    "up_kegg_conn_dict = {'src': up_src_list, 'dest': up_dest_list}\n",
    "up_kegg_df = pd.DataFrame(up_kegg_conn_dict)\n",
    "up_kegg_df = up_kegg_df.drop_duplicates()\n",
    "up_kegg_df.to_csv('./data/kg_data/KEGG/up_kegg.csv', index=False, header=True)\n",
    "kegg_gene_list = list(set(list(up_kegg_df['src']) + list(up_kegg_df['dest'])))\n",
    "print('----- NUMBER OF GENES IN KEGG: ' + str(len(kegg_gene_list)) + ' -----')\n",
    "print(up_kegg_df.shape)\n",
    "\n",
    "up_kegg_path_conn_dict = {'src': up_src_list, 'dest': up_dest_list, 'path': path_list}\n",
    "up_kegg_path_df = pd.DataFrame(up_kegg_path_conn_dict)\n",
    "up_kegg_path_df = up_kegg_path_df.drop_duplicates()\n",
    "up_kegg_path_df.to_csv('./data/kg_data/KEGG/up_kegg_path.csv', index=False, header=True)\n",
    "kegg_path_gene_list = list(set(list(up_kegg_path_df['src']) + list(up_kegg_path_df['dest'])))\n",
    "print('----- NUMBER OF GENES IN KEGG PATH: ' + str(len(kegg_path_gene_list)) + ' -----')\n",
    "print(up_kegg_path_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioGRID\n",
    "biogrid_df = pd.read_table('./data/kg_data/BioGrid/BIOGRID-ALL-3.5.174.mitab.Symbol.txt', delimiter = '\\t')\n",
    "eh_list = list(biogrid_df['e_h'])\n",
    "et_list = list(biogrid_df['e_t'])\n",
    "# ADJUST ALL GENES TO UPPERCASE\n",
    "up_eh_list = []\n",
    "for eh in eh_list:\n",
    "    up_eh = eh.upper()\n",
    "    up_eh_list.append(up_eh)\n",
    "up_et_list = []\n",
    "for et in et_list:\n",
    "    up_et = et.upper()\n",
    "    up_et_list.append(up_et)\n",
    "up_biogrid_conn_dict = {'src': up_eh_list, 'dest': up_et_list}\n",
    "up_biogrid_df = pd.DataFrame(up_biogrid_conn_dict)\n",
    "up_biogrid_df = up_biogrid_df.drop_duplicates()\n",
    "print(up_biogrid_df)\n",
    "up_biogrid_df.to_csv('./data/kg_data/BioGrid/up_biogrid.csv', index = False, header = True)\n",
    "up_biogrid_gene_list = list(set(list(up_biogrid_df['src']) + list(up_biogrid_df['dest'])))\n",
    "print('----- NUMBER OF GENES IN BioGRID: ' + str(len(up_biogrid_gene_list)) + ' -----')\n",
    "print(up_biogrid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STRING\n",
    "string_df = pd.read_csv('./data/kg_data/STRING/9606.protein.links.detailed.v11.0_sym.csv', low_memory=False)\n",
    "src_list = list(string_df['Source'])\n",
    "tar_list = list(string_df['Target'])\n",
    "# ADJUST ALL GENES TO UPPERCASE\n",
    "up_src_list = []\n",
    "for src in src_list:\n",
    "    up_src = src.upper()\n",
    "    up_src_list.append(up_src)\n",
    "up_tar_list = []\n",
    "for tar in tar_list:\n",
    "    up_tar = tar.upper()\n",
    "    up_tar_list.append(up_tar)\n",
    "up_string_conn_dict = {'src': up_src_list, 'dest': up_tar_list}\n",
    "up_string_df = pd.DataFrame(up_string_conn_dict)\n",
    "up_string_df = up_string_df.drop_duplicates()\n",
    "print(up_string_df)\n",
    "up_string_df.to_csv('./data/kg_data/STRING/up_string.csv', index = False, header = True)\n",
    "up_string_gene_list = list(set(list(up_string_df['src']) + list(up_string_df['dest'])))\n",
    "print('----- NUMBER OF GENES IN STRING: ' + str(len(up_string_gene_list)) + ' -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intersect the [common genes] with the genes in the different databases [KEGG / BioGRID / STRING]\n",
    "selected_database = 'KEGG'\n",
    "# selected_database = 'BioGRID'\n",
    "# selected_database = 'STRING'\n",
    "intersected_omics_gene_list = list(merged_tran_v1_df['gene_name'])\n",
    "if selected_database == 'KEGG':\n",
    "    edge_common_genes = list(set(intersected_omics_gene_list) & set(kegg_gene_list))\n",
    "elif selected_database == 'BioGRID':\n",
    "    edge_common_genes = list(set(intersected_omics_gene_list) & set(up_biogrid_gene_list))\n",
    "elif selected_database == 'STRING':\n",
    "    edge_common_genes = list(set(intersected_omics_gene_list) & set(up_string_gene_list))\n",
    "\n",
    "# filter the genes in the different databases [KEGG / BioGRID / STRING] with the [common genes]\n",
    "if selected_database == 'KEGG':\n",
    "    filtered_up_kegg_df = up_kegg_df[up_kegg_df['src'].isin(edge_common_genes) & up_kegg_df['dest'].isin(edge_common_genes)]\n",
    "    src_list = list(filtered_up_kegg_df['src'])\n",
    "    dest_list = list(filtered_up_kegg_df['dest'])\n",
    "    all_edge_gene_list = sorted(list(set(src_list + dest_list)))\n",
    "    print('----- NUMBER OF INTERSECTED GENES IN KEGG: ' + str(len(all_edge_gene_list)) + ' -----')\n",
    "    edge_common_genes = all_edge_gene_list\n",
    "    filtered_up_kegg_df = filtered_up_kegg_df.drop_duplicates()\n",
    "    filtered_up_kegg_df = filtered_up_kegg_df.sort_values(by=['src', 'dest']).reset_index(drop=True)\n",
    "    print('----- NEW KEGG EDGE CONNECTIONS: ' + str(len(filtered_up_kegg_df)) + ' -----')\n",
    "    filtered_up_kegg_path_df = up_kegg_path_df[up_kegg_path_df['src'].isin(edge_common_genes) & up_kegg_path_df['dest'].isin(edge_common_genes)]\n",
    "    filtered_up_kegg_path_df = filtered_up_kegg_path_df.drop_duplicates()\n",
    "    filtered_up_kegg_path_df = filtered_up_kegg_path_df.sort_values(by=['src', 'dest']).reset_index(drop=True)\n",
    "    print('----- NEW KEGG PATHWAY CONNECTIONS: ' + str(len(filtered_up_kegg_path_df)) + ' -----')\n",
    "if selected_database == 'BioGRID':\n",
    "    filtered_up_biogrid_df = up_biogrid_df[up_biogrid_df['src'].isin(edge_common_genes) & up_biogrid_df['dest'].isin(edge_common_genes)]\n",
    "    src_list = list(filtered_up_biogrid_df['src'])\n",
    "    dest_list = list(filtered_up_biogrid_df['dest'])\n",
    "    all_edge_gene_list = sorted(list(set(src_list + dest_list)))\n",
    "    print('----- NUMBER OF INTERSECTED GENES IN BioGRID: ' + str(len(all_edge_gene_list)) + ' -----')\n",
    "    edge_common_genes = all_edge_gene_list\n",
    "    filtered_up_biogrid_df = filtered_up_biogrid_df.drop_duplicates()\n",
    "    filtered_up_biogrid_df = filtered_up_biogrid_df.sort_values(by=['src', 'dest']).reset_index(drop=True)\n",
    "    print('----- NEW BioGRID EDGE CONNECTIONS: ' + str(len(filtered_up_biogrid_df)) + ' -----')\n",
    "if selected_database == 'STRING':\n",
    "    filtered_up_string_df = up_string_df[up_string_df['src'].isin(edge_common_genes) & up_string_df['dest'].isin(edge_common_genes)]\n",
    "    src_list = list(filtered_up_string_df['src'])\n",
    "    dest_list = list(filtered_up_string_df['dest'])\n",
    "    all_edge_gene_list = sorted(list(set(src_list + dest_list)))\n",
    "    print('----- NUMBER OF INTERSECTED GENES IN STRING: ' + str(len(all_edge_gene_list)) + ' -----')\n",
    "    edge_common_genes = all_edge_gene_list\n",
    "    filtered_up_string_df = filtered_up_string_df.drop_duplicates()\n",
    "    filtered_up_string_df = filtered_up_string_df.sort_values(by=['src', 'dest']).reset_index(drop=True)\n",
    "    print('----- NEW STRING EDGE CONNECTIONS: ' + str(len(filtered_up_string_df)) + ' -----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the omics genes in the different databases [KEGG / BioGRID / STRING] with the [all_edge_gene_list]\n",
    "merged_tran_v1_df = merged_tran_v1_df[merged_tran_v1_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "merged_core_promoter_df = merged_core_promoter_df[merged_core_promoter_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "merged_distal_promoter_df = merged_distal_promoter_df[merged_distal_promoter_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "merged_downstream_df = merged_downstream_df[merged_downstream_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "merged_proximal_promoter_df = merged_proximal_promoter_df[merged_proximal_promoter_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "merged_upstream_df = merged_upstream_df[merged_upstream_df['gene_name'].isin(all_edge_gene_list)].reset_index(drop=True)\n",
    "display(merged_tran_v1_df)\n",
    "display(merged_upstream_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Important GWAS Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t6_df = pd.read_csv('./data/gwas_data/t6.txt', delimiter = '\\t')\n",
    "t6_genes = t6_df['Locus'].tolist()\n",
    "gene_names_list = merged_tran_v1_df['gene_name'].tolist()\n",
    "t6_common_genes = list(set(gene_names_list) & set(t6_genes))\n",
    "print('t6_common_genes:', len(t6_common_genes))\n",
    "print(t6_common_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sample Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check intersection of subjects between the phenodata and omics data\n",
    "subject_list = phenodata_df['subject'].tolist()\n",
    "t2ds_label_subject_list = t2ds_label_df['subject'].tolist()\n",
    "merged_tran_v1_subject_list = merged_tran_v1_df.columns.tolist()[1:]\n",
    "merged_upstream_subject_list = merged_upstream_df.columns.tolist()[1:]\n",
    "intersected_subject_list = sorted(list(set(subject_list) & set(t2ds_label_subject_list) & set(merged_tran_v1_subject_list) & set(merged_upstream_subject_list)))\n",
    "# Even this is the string, sort the list by numerical order\n",
    "intersected_subject_list = sorted(intersected_subject_list, key=lambda x: int(x))\n",
    "print('Number of intersected subjects:', len(intersected_subject_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subjects that are in both the phenodata and omics data\n",
    "phenodata_df = phenodata_df[phenodata_df['subject'].isin(intersected_subject_list)].reset_index(drop=True)\n",
    "t2ds_label_df = t2ds_label_df[t2ds_label_df['subject'].isin(intersected_subject_list)].reset_index(drop=True)\n",
    "merged_tran_v1_df = merged_tran_v1_df[['gene_name'] + intersected_subject_list]\n",
    "merged_core_promoter_df = merged_core_promoter_df[['gene_name'] + intersected_subject_list]\n",
    "merged_distal_promoter_df = merged_distal_promoter_df[['gene_name'] + intersected_subject_list]\n",
    "merged_downstream_df = merged_downstream_df[['gene_name'] + intersected_subject_list]\n",
    "merged_proximal_promoter_df = merged_proximal_promoter_df[['gene_name'] + intersected_subject_list]\n",
    "merged_upstream_df = merged_upstream_df[['gene_name'] + intersected_subject_list]\n",
    "display(phenodata_df)\n",
    "display(t2ds_label_df)\n",
    "display(merged_tran_v1_df)\n",
    "display(merged_upstream_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Statistical Analysis on Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### filter out different labels\n",
    "t2ds_df = t2ds_label_df[t2ds_label_df['t2ds'] == 1]['subject']\n",
    "pret2ds_df = t2ds_label_df[t2ds_label_df['pret2ds'] == 1]['subject']\n",
    "no_t2ds_df = t2ds_label_df[(t2ds_label_df['t2ds'] != 1 ) & (t2ds_label_df['pret2ds'] != 1)]['subject']\n",
    "# check the intersection\n",
    "# t2ds\n",
    "t2ds_list = list(t2ds_df) \n",
    "t2ds_set = set(t2ds_list)\n",
    "# pret2ds\n",
    "pret2ds_list = list(pret2ds_df)\n",
    "pret2ds_set = set(pret2ds_list)\n",
    "# no_t2ds\n",
    "no_t2ds_list = list(no_t2ds_df)\n",
    "no_t2ds_set = set(no_t2ds_list)\n",
    "# [t2ds / pret2ds]\n",
    "t2ds_pret2ds_intersection = t2ds_set.intersection(pret2ds_set)\n",
    "if t2ds_pret2ds_intersection==set(): print('No intersections of t2ds and pret2ds')\n",
    "# [t2ds / no_t2ds]\n",
    "t2ds_no_t2ds_intersection = t2ds_set.intersection(no_t2ds_set)\n",
    "if t2ds_no_t2ds_intersection==set(): print('No intersections of t2ds and no_t2ds')\n",
    "# [pret2ds / no_t2ds]\n",
    "pret2ds_no_t2ds_intersection = pret2ds_set.intersection(no_t2ds_set)\n",
    "if pret2ds_no_t2ds_intersection==set(): print('No intersections of pret2ds and no_t2ds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Cleaning clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cleaning clinical data [phenodata_df]\n",
    "# intersections between label and clinical data\n",
    "label_phenodata_df = phenodata_df.merge(t2ds_label_df, left_on='subject', right_on='subject', how='inner')\n",
    "label_phenodata_df = label_phenodata_df.drop(columns=['t2ds', 'pret2ds'])\n",
    "label_phenodata_df = label_phenodata_df.dropna(subset=['id'])\n",
    "# check v1 features, v2 features and their intersections \n",
    "label_phenodata_df_col_name_list = list(label_phenodata_df.columns)\n",
    "print(len(label_phenodata_df_col_name_list))\n",
    "print(label_phenodata_df_col_name_list)\n",
    "# v1 features\n",
    "label_phenodata_df_v1_col_name_list = [col for col in label_phenodata_df_col_name_list if '_v1' in col]\n",
    "print('--- Number of v1: ', len(label_phenodata_df_v1_col_name_list))\n",
    "label_phenodata_df_v1_col_realname_list = [name.removesuffix('_v1') for name in label_phenodata_df_v1_col_name_list]\n",
    "print(label_phenodata_df_v1_col_realname_list)\n",
    "# v2 features\n",
    "label_phenodata_df_v2_col_name_list = [col for col in label_phenodata_df_col_name_list if '_v2' in col]\n",
    "print('--- Number of v2: ', len(label_phenodata_df_v2_col_name_list))\n",
    "label_phenodata_df_v2_col_realname_list = [name.removesuffix('_v2') for name in label_phenodata_df_v2_col_name_list]\n",
    "print(label_phenodata_df_v2_col_realname_list)\n",
    "# gc [growth curve model] features\n",
    "label_phenodata_df_gc_col_name_list = [col for col in label_phenodata_df_col_name_list if '_gc' in col]\n",
    "print('--- Number of gc: ', len(label_phenodata_df_gc_col_name_list))\n",
    "label_phenodata_df_gc_col_realname_list = [name.removesuffix('_gc') for name in label_phenodata_df_gc_col_name_list]\n",
    "print(label_phenodata_df_gc_col_realname_list)\n",
    "# ns [naive slope (simple regression)] features\n",
    "label_phenodata_df_ns_col_name_list = [col for col in label_phenodata_df_col_name_list if '_ns' in col]\n",
    "print('--- Number of ns: ', len(label_phenodata_df_ns_col_name_list))\n",
    "label_phenodata_df_ns_col_realname_list = [name.removesuffix('_ns') for name in label_phenodata_df_ns_col_name_list]\n",
    "print(label_phenodata_df_ns_col_realname_list)\n",
    "# Not known class features\n",
    "v1_v2_gc_ns_list = label_phenodata_df_v1_col_name_list + label_phenodata_df_v2_col_name_list +\\\n",
    "                         label_phenodata_df_gc_col_name_list + label_phenodata_df_ns_col_name_list\n",
    "not_known_col_name_list = [name for name in label_phenodata_df_col_name_list if name not in v1_v2_gc_ns_list]\n",
    "print('--- Number of not known features: ', len(not_known_col_name_list))\n",
    "print(not_known_col_name_list)\n",
    "# [v1 / v2] intersection\n",
    "v1_v2_intersection_set = set(label_phenodata_df_v1_col_realname_list).intersection(set(label_phenodata_df_v2_col_realname_list))\n",
    "print('--- Number of intersected features of v1 & v2: ', len(v1_v2_intersection_set))\n",
    "print(v1_v2_intersection_set)\n",
    "\n",
    "# reserve only first visit columns [v1]\n",
    "label_phenodata_df_id_v1_col_name_list = not_known_col_name_list + label_phenodata_df_v1_col_name_list\n",
    "redundant_feat_list = ['teststrnz_invn_v1', 'srage_logz_invn_v1', 'il6_logz_invn_v1', 'tg_logz_v1', 'ldlz_v1', 'igf1_invnz_v1', 'hdlz_v1', 'hba1cz_v1', 'glucz_v1', 'dhea_logz_v1', '_ins_logz_v1', 'A1Cz_v1']\n",
    "label_phenodata_df_id_v1_col_name_list = [item for item in label_phenodata_df_id_v1_col_name_list if item not in redundant_feat_list]\n",
    "print(label_phenodata_df_id_v1_col_name_list)\n",
    "v1_label_phenodata_df = label_phenodata_df[label_phenodata_df_id_v1_col_name_list]\n",
    "# # check v1 are all float types\n",
    "# pd.set_option('display.max_rows', 120)\n",
    "# print(v1_label_phenodata_df.dtypes)\n",
    "\n",
    "# data imputation by replacing nan values\n",
    "v1_label_phenodata_nan_col_list = v1_label_phenodata_df.columns[v1_label_phenodata_df.isna().any()].tolist()\n",
    "for nan_col_name in v1_label_phenodata_nan_col_list:\n",
    "    v1_label_phenodata_df[nan_col_name] = v1_label_phenodata_df[nan_col_name].fillna(v1_label_phenodata_df[nan_col_name].mean())\n",
    "\n",
    "# check if there are any NaN values in the DataFrame\n",
    "if v1_label_phenodata_df.isnull().values.any():\n",
    "    print('\\n--- DataFrame contains NaN values ---\\n')\n",
    "else:\n",
    "    print('\\n--- DataFrame does not contain NaN values ---\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique value\n",
    "pd.set_option('display.max_rows', 10)\n",
    "display(v1_label_phenodata_df)\n",
    "print(v1_label_phenodata_df.shape)\n",
    "print(v1_label_phenodata_df.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Statistical analysis for clinical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stat analysis for clinical features\n",
    "# [423 t2ds] in clinical dataframe\n",
    "t2ds_phenodata_df = v1_label_phenodata_df[v1_label_phenodata_df['subject'].isin(t2ds_list)].reset_index(drop=True)\n",
    "display(t2ds_phenodata_df)\n",
    "# [588 pret2ds] in clinical dataframe\n",
    "pret2ds_phenodata_df = v1_label_phenodata_df[v1_label_phenodata_df['subject'].isin(pret2ds_list)].reset_index(drop=True)\n",
    "display(pret2ds_phenodata_df)\n",
    "# [3788 no_t2ds] in clinical dataframe\n",
    "no_t2ds_phenodata_df = v1_label_phenodata_df[v1_label_phenodata_df['subject'].isin(no_t2ds_list)].reset_index(drop=True)\n",
    "display(no_t2ds_phenodata_df)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import mannwhitneyu\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "# label_phenodata_df_rvid_v1_col_name_list = label_phenodata_df_id_v1_col_name_list[4:]\n",
    "label_phenodata_df_rvid_v1_col_name_list = label_phenodata_df_id_v1_col_name_list[5:] # remove sex feature\n",
    "print(label_phenodata_df_id_v1_col_name_list)\n",
    "print(label_phenodata_df_rvid_v1_col_name_list)\n",
    "for col_name in label_phenodata_df_rvid_v1_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_phenodata_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_phenodata_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_phenodata_df[col_name])\n",
    "    # if col_name == 'sex':\n",
    "    #     # [t2ds / pret2ds]\n",
    "    #     _, p_value_mw_t2ds_pret2ds = mannwhitneyu(t2ds_feature_list, pret2ds_feature_list)\n",
    "    #     p_value_ks_t2ds_pret2ds_list.append(p_value_mw_t2ds_pret2ds)\n",
    "    #     print('[t2ds/ pret2ds] Mann-Whitney U test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    #     # [t2ds / no_t2ds]\n",
    "    #     _, p_value_mw_t2ds_no_t2ds = mannwhitneyu(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    #     p_value_ks_t2ds_no_t2ds_list.append(p_value_mw_t2ds_no_t2ds)\n",
    "    #     print('[t2ds/ no_t2ds] Mann-Whitney U test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    #     # [pret2ds / no_t2ds]\n",
    "    #     _, p_value_mw_pret2ds_no_t2ds = mannwhitneyu(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    #     p_value_ks_pret2ds_no_t2ds_list.append(p_value_mw_pret2ds_no_t2ds)\n",
    "    #     print('[pret2ds/ no_t2ds] Mann-Whitney U test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "    # else:\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "print(len(label_phenodata_df_rvid_v1_col_name_list))\n",
    "print(len(p_value_ks_t2ds_pret2ds_list))\n",
    "print(len(p_value_ks_t2ds_no_t2ds_list))\n",
    "print(len(p_value_ks_pret2ds_no_t2ds_list))\n",
    "\n",
    "label_phenodata_rvid_v1_col_name_pvalue_df = pd.DataFrame({\n",
    "    'features': label_phenodata_df_rvid_v1_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "import os\n",
    "if os.path.exists('./data/stat_data/') == False:\n",
    "    os.mkdir('./data/stat_data/')\n",
    "label_phenodata_rvid_v1_col_name_pvalue_df.to_csv('./data/stat_data/label_phenodata_rvid_v1_col_name_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_phenodata_df_rvid_v1_continous_name_list = label_phenodata_df_id_v1_col_name_list[5:] # remove [sex]\n",
    "t2ds_phenodata_average_list = t2ds_phenodata_df[label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()\n",
    "pret2ds_phenodata_average_list = pret2ds_phenodata_df[label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()\n",
    "no_t2ds_phenodata_average_list = no_t2ds_phenodata_df[label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_value_ks_pret2ds_no_t2ds_list)\n",
    "print(len(p_value_ks_pret2ds_no_t2ds_list))\n",
    "print(label_phenodata_df_rvid_v1_continous_name_list)\n",
    "print(len(label_phenodata_df_rvid_v1_continous_name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import pandas as pd\n",
    "\n",
    "cmap = 'Oranges_r'\n",
    "# cmap = 'Oranges'\n",
    "list1 = p_value_ks_t2ds_pret2ds_list\n",
    "list2 = p_value_ks_t2ds_no_t2ds_list\n",
    "list3 = p_value_ks_pret2ds_no_t2ds_list\n",
    "\n",
    "#retrieve unique labels\n",
    "ylabels = label_phenodata_df_rvid_v1_continous_name_list\n",
    "print(len(ylabels))\n",
    "xlabels = ['T2ds vs Pre_T2ds', 'T2ds vs No_T2ds', 'Pre_T2ds vs No_T2ds']\n",
    "ylabels_num_list = list(np.arange(0, len(ylabels))) + list(np.arange(0, len(ylabels))) + list(np.arange(0, len(ylabels)))\n",
    "xlabels_num_list = len(ylabels) * [0] + len(ylabels) * [1] + len(ylabels) * [2]\n",
    "xn = len(xlabels)\n",
    "yn = len(ylabels)\n",
    "#retrieve size and color information    \n",
    "s = np.array(list1 + list2 + list3)\n",
    "c = np.array(list1 + list2 + list3)\n",
    "\n",
    "#preparation of the figure with its grid\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "ax.set_xlim(-0.5, xn-0.5)\n",
    "ax.set_ylim(-0.5, yn-0.5)\n",
    "ax.set(xticks=np.arange(xn), yticks=np.arange(yn),\n",
    "       xticklabels=xlabels, yticklabels=ylabels)\n",
    "\n",
    "ax.set_xticks(np.arange(xn)-0.5, minor=True)\n",
    "ax.set_yticks(np.arange(yn)-0.5, minor=True)\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "# plt.xticks(rotation=90)\n",
    "ax.grid(which='minor')\n",
    "#ensure circles are displayed as circles\n",
    "ax.set_aspect(\"equal\", \"box\")\n",
    "\n",
    "#create circles patches and colorbar\n",
    "# R = 0.4 - s/s.max()/2\n",
    "R = [0.3] * len(s)\n",
    "# R = 0.3-s/(s.max()/0.3)\n",
    "circles = [plt.Circle((xlabels_num_list[i], ylabels_num_list[i]), radius=r) for i, r in enumerate(R)]\n",
    "norm = TwoSlopeNorm(vmin=0, vmax=1, vcenter=0.1)\n",
    "col = PatchCollection(circles, array=c, cmap=cmap, norm=norm)\n",
    "ax.add_collection(col)\n",
    "fig.colorbar(col, shrink=0.2, aspect=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_label_phenodata_df_rvid_v1_continous_name_list = label_phenodata_df_id_v1_col_name_list[6:] # remove [sex, age]\n",
    "bar_t2ds_phenodata_average_list = t2ds_phenodata_df[bar_label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()\n",
    "bar_pret2ds_phenodata_average_list = pret2ds_phenodata_df[bar_label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()\n",
    "bar_no_t2ds_phenodata_average_list = no_t2ds_phenodata_df[bar_label_phenodata_df_rvid_v1_continous_name_list].mean().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for three bar plots\n",
    "x1 = np.array(bar_t2ds_phenodata_average_list)\n",
    "x2 = np.array(bar_pret2ds_phenodata_average_list)\n",
    "x3 = np.array(bar_no_t2ds_phenodata_average_list)\n",
    "y1 = np.array(bar_label_phenodata_df_rvid_v1_continous_name_list)\n",
    "\n",
    "# Create a figure and subplots with shared y-axis\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
    "\n",
    "# Set colors for each bar plot\n",
    "colors = ['C0', 'C1', 'C2']\n",
    "\n",
    "# Plot the first bar plot\n",
    "axes[0].barh(y1, x1, color=colors[0])\n",
    "axes[0].set_title('T2ds bar plot')\n",
    "\n",
    "# Plot the second bar plot\n",
    "axes[1].barh(y1, x2, color=colors[1])\n",
    "axes[1].set_title('Pre_T2ds bar plot')\n",
    "\n",
    "# Plot the third bar plot\n",
    "axes[2].barh(y1, x3, color=colors[2])\n",
    "axes[2].set_title('No_T2ds bar plot')\n",
    "\n",
    "# Set common labels and title for the subplots\n",
    "fig.text(0.5, -0.04, 'Average Values for Each Type of Patient', ha='center')\n",
    "fig.text(-0.01, 0.5, 'Visit 1 Features', va='center', rotation='vertical')\n",
    "fig.suptitle('Three Classifications of Patients Bar Plots')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Statistical analysis with Fold-Change for clinical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_log2_fold_change(sample1, sample2):\n",
    "    fold_change = sample2 / sample1\n",
    "    log2_fold_change = math.log2(fold_change)\n",
    "    return log2_fold_change\n",
    "\n",
    "def sample_log2_fold_change_comparison(list1, list2):\n",
    "    log2_fold_change_list = []\n",
    "    for sample1, sample2 in zip(list1, list2):\n",
    "        log2_fold_change = calculate_log2_fold_change(sample1, sample2)\n",
    "        log2_fold_change_list.append(log2_fold_change)\n",
    "    \n",
    "    print(\"Log2 fold changes:\")\n",
    "    for i, log2_fc in enumerate(log2_fold_changes):\n",
    "        print(f\"Sample {i+1}: {log2_fc}\")\n",
    "\n",
    "    return log2_fold_change_list\n",
    "\n",
    "# # Fold-change comparisons with math domain error (cause the elements in the those lists have negative values)\n",
    "# t2ds_pret2ds_fold_change_list = sample_log2_fold_change_comparison(t2ds_phenodata_average_list, pret2ds_phenodata_average_list)\n",
    "# t2ds_no_t2ds_fold_change_list = sample_log2_fold_change_comparison(t2ds_phenodata_average_list, no_t2ds_phenodata_average_list)\n",
    "# pret2ds_no_t2ds_fold_change_list = sample_log2_fold_change_comparison(pret2ds_phenodata_average_list, no_t2ds_phenodata_average_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Statistical analysis for transcriptomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subject in the columns for certain types of patients\n",
    "t2ds_merged_tran_v1_df = merged_tran_v1_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "display(t2ds_merged_tran_v1_df)\n",
    "t2ds_merged_tran_v1_transposed_df = t2ds_merged_tran_v1_df.T\n",
    "t2ds_merged_tran_v1_transposed_df.columns = t2ds_merged_tran_v1_transposed_df.iloc[0]\n",
    "t2ds_merged_tran_v1_transposed_df = t2ds_merged_tran_v1_transposed_df[1:] \n",
    "# convert index to first column with the name 'subject' and remove the index name\n",
    "t2ds_merged_tran_v1_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_tran_v1_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "display(t2ds_merged_tran_v1_transposed_df)\n",
    "\n",
    "pret2ds_merged_tran_v1_df = merged_tran_v1_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "display(pret2ds_merged_tran_v1_df)\n",
    "pret2ds_merged_tran_v1_transposed_df = pret2ds_merged_tran_v1_df.T\n",
    "pret2ds_merged_tran_v1_transposed_df.columns = pret2ds_merged_tran_v1_transposed_df.iloc[0]\n",
    "pret2ds_merged_tran_v1_transposed_df = pret2ds_merged_tran_v1_transposed_df[1:]\n",
    "pret2ds_merged_tran_v1_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_tran_v1_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "display(pret2ds_merged_tran_v1_transposed_df)\n",
    "\n",
    "no_t2ds_merged_tran_v1_df = merged_tran_v1_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "display(no_t2ds_merged_tran_v1_df)\n",
    "no_t2ds_merged_tran_v1_transposed_df = no_t2ds_merged_tran_v1_df.T\n",
    "no_t2ds_merged_tran_v1_transposed_df.columns = no_t2ds_merged_tran_v1_transposed_df.iloc[0]\n",
    "no_t2ds_merged_tran_v1_transposed_df = no_t2ds_merged_tran_v1_transposed_df[1:]\n",
    "no_t2ds_merged_tran_v1_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_tran_v1_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "display(no_t2ds_merged_tran_v1_transposed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_tran_v1_col_name_list = list(t2ds_merged_tran_v1_transposed_df.columns)[1:]\n",
    "for col_name in merged_tran_v1_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_tran_v1_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_tran_v1_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_tran_v1_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_transcriptomics_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_tran_v1_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_transcriptomics_pvalue_df)\n",
    "merged_transcriptomics_pvalue_df.to_csv('./data/stat_data/merged_transcriptomics_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Statistical analysis for epigenomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keep the subject in the columns for certain types of patients for core promoters\n",
    "# t2ds for core promoters\n",
    "t2ds_merged_core_promoter_df = merged_core_promoter_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "t2ds_merged_core_promoter_transposed_df = t2ds_merged_core_promoter_df.T\n",
    "t2ds_merged_core_promoter_transposed_df.columns = t2ds_merged_core_promoter_transposed_df.iloc[0]\n",
    "t2ds_merged_core_promoter_transposed_df = t2ds_merged_core_promoter_transposed_df[1:]\n",
    "t2ds_merged_core_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_core_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# pret2ds for core promoters\n",
    "pret2ds_merged_core_promoter_df = merged_core_promoter_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "pret2ds_merged_core_promoter_transposed_df = pret2ds_merged_core_promoter_df.T\n",
    "pret2ds_merged_core_promoter_transposed_df.columns = pret2ds_merged_core_promoter_transposed_df.iloc[0]\n",
    "pret2ds_merged_core_promoter_transposed_df = pret2ds_merged_core_promoter_transposed_df[1:]\n",
    "pret2ds_merged_core_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_core_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# no_t2ds for core promoters\n",
    "no_t2ds_merged_core_promoter_df = merged_core_promoter_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "no_t2ds_merged_core_promoter_transposed_df = no_t2ds_merged_core_promoter_df.T\n",
    "no_t2ds_merged_core_promoter_transposed_df.columns = no_t2ds_merged_core_promoter_transposed_df.iloc[0]\n",
    "no_t2ds_merged_core_promoter_transposed_df = no_t2ds_merged_core_promoter_transposed_df[1:]\n",
    "no_t2ds_merged_core_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_core_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_core_promoter_col_name_list = list(t2ds_merged_core_promoter_transposed_df.columns)[1:]\n",
    "for col_name in merged_core_promoter_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_core_promoter_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_core_promoter_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_core_promoter_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_core_promoter_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_core_promoter_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_core_promoter_pvalue_df)\n",
    "merged_core_promoter_pvalue_df.to_csv('./data/stat_data/merged_core_promoter_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subject in the columns for certain types of patients for proximal promoters\n",
    "# t2ds for proximal promoters\n",
    "t2ds_merged_proximal_promoter_df = merged_proximal_promoter_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "t2ds_merged_proximal_promoter_transposed_df = t2ds_merged_proximal_promoter_df.T\n",
    "t2ds_merged_proximal_promoter_transposed_df.columns = t2ds_merged_proximal_promoter_transposed_df.iloc[0]\n",
    "t2ds_merged_proximal_promoter_transposed_df = t2ds_merged_proximal_promoter_transposed_df[1:]\n",
    "t2ds_merged_proximal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_proximal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# pret2ds for proximal promoters\n",
    "pret2ds_merged_proximal_promoter_df = merged_proximal_promoter_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "pret2ds_merged_proximal_promoter_transposed_df = pret2ds_merged_proximal_promoter_df.T\n",
    "pret2ds_merged_proximal_promoter_transposed_df.columns = pret2ds_merged_proximal_promoter_transposed_df.iloc[0]\n",
    "pret2ds_merged_proximal_promoter_transposed_df = pret2ds_merged_proximal_promoter_transposed_df[1:]\n",
    "pret2ds_merged_proximal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_proximal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# no_t2ds for proximal promoters\n",
    "no_t2ds_merged_proximal_promoter_df = merged_proximal_promoter_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "no_t2ds_merged_proximal_promoter_transposed_df = no_t2ds_merged_proximal_promoter_df.T\n",
    "no_t2ds_merged_proximal_promoter_transposed_df.columns = no_t2ds_merged_proximal_promoter_transposed_df.iloc[0]\n",
    "no_t2ds_merged_proximal_promoter_transposed_df = no_t2ds_merged_proximal_promoter_transposed_df[1:]\n",
    "no_t2ds_merged_proximal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_proximal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_proximal_promoter_col_name_list = list(t2ds_merged_proximal_promoter_transposed_df.columns)[1:]\n",
    "for col_name in merged_proximal_promoter_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_proximal_promoter_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_proximal_promoter_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_proximal_promoter_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_proximal_promoter_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_proximal_promoter_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_proximal_promoter_pvalue_df)\n",
    "merged_proximal_promoter_pvalue_df.to_csv('./data/stat_data/merged_proximal_promoter_pvalue.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subject in the columns for certain types of patients for distal promoters\n",
    "# t2ds for distal promoters\n",
    "t2ds_merged_distal_promoter_df = merged_distal_promoter_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "t2ds_merged_distal_promoter_transposed_df = t2ds_merged_distal_promoter_df.T\n",
    "t2ds_merged_distal_promoter_transposed_df.columns = t2ds_merged_distal_promoter_transposed_df.iloc[0]\n",
    "t2ds_merged_distal_promoter_transposed_df = t2ds_merged_distal_promoter_transposed_df[1:]\n",
    "t2ds_merged_distal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_distal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# pret2ds for distal promoters\n",
    "pret2ds_merged_distal_promoter_df = merged_distal_promoter_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "pret2ds_merged_distal_promoter_transposed_df = pret2ds_merged_distal_promoter_df.T\n",
    "pret2ds_merged_distal_promoter_transposed_df.columns = pret2ds_merged_distal_promoter_transposed_df.iloc[0]\n",
    "pret2ds_merged_distal_promoter_transposed_df = pret2ds_merged_distal_promoter_transposed_df[1:]\n",
    "pret2ds_merged_distal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_distal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# no_t2ds for distal promoters\n",
    "no_t2ds_merged_distal_promoter_df = merged_distal_promoter_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "no_t2ds_merged_distal_promoter_transposed_df = no_t2ds_merged_distal_promoter_df.T\n",
    "no_t2ds_merged_distal_promoter_transposed_df.columns = no_t2ds_merged_distal_promoter_transposed_df.iloc[0]\n",
    "no_t2ds_merged_distal_promoter_transposed_df = no_t2ds_merged_distal_promoter_transposed_df[1:]\n",
    "no_t2ds_merged_distal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_distal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_distal_promoter_col_name_list = list(t2ds_merged_distal_promoter_transposed_df.columns)[1:]\n",
    "for col_name in merged_distal_promoter_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_distal_promoter_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_distal_promoter_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_distal_promoter_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_distal_promoter_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_distal_promoter_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_distal_promoter_pvalue_df)\n",
    "merged_distal_promoter_pvalue_df.to_csv('./data/stat_data/merged_distal_promoter_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subject in the columns for certain types of patients for distal promoters\n",
    "# t2ds for distal promoters\n",
    "t2ds_merged_upstream_df = merged_upstream_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "t2ds_merged_upstream_transposed_df = t2ds_merged_upstream_df.T\n",
    "t2ds_merged_upstream_transposed_df.columns = t2ds_merged_upstream_transposed_df.iloc[0]\n",
    "t2ds_merged_upstream_transposed_df = t2ds_merged_upstream_transposed_df[1:]\n",
    "t2ds_merged_upstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_upstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# pret2ds for distal promoters\n",
    "pret2ds_merged_upstream_df = merged_upstream_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "pret2ds_merged_upstream_transposed_df = pret2ds_merged_upstream_df.T\n",
    "pret2ds_merged_upstream_transposed_df.columns = pret2ds_merged_upstream_transposed_df.iloc[0]\n",
    "pret2ds_merged_upstream_transposed_df = pret2ds_merged_upstream_transposed_df[1:]\n",
    "pret2ds_merged_upstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_upstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# no_t2ds for distal promoters\n",
    "no_t2ds_merged_upstream_df = merged_upstream_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "no_t2ds_merged_upstream_transposed_df = no_t2ds_merged_upstream_df.T\n",
    "no_t2ds_merged_upstream_transposed_df.columns = no_t2ds_merged_upstream_transposed_df.iloc[0]\n",
    "no_t2ds_merged_upstream_transposed_df = no_t2ds_merged_upstream_transposed_df[1:]\n",
    "no_t2ds_merged_upstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_upstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_upstream_col_name_list = list(t2ds_merged_upstream_transposed_df.columns)[1:]\n",
    "for col_name in merged_upstream_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_upstream_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_upstream_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_upstream_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_upstream_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_upstream_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_upstream_pvalue_df)\n",
    "merged_upstream_pvalue_df.to_csv('./data/stat_data/merged_upstream_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep the subject in the columns for certain types of patients for distal promoters\n",
    "# t2ds for distal promoters\n",
    "t2ds_merged_downstream_df = merged_downstream_df[['gene_name'] + t2ds_list] # [68 t2ds]\n",
    "t2ds_merged_downstream_transposed_df = t2ds_merged_downstream_df.T\n",
    "t2ds_merged_downstream_transposed_df.columns = t2ds_merged_downstream_transposed_df.iloc[0]\n",
    "t2ds_merged_downstream_transposed_df = t2ds_merged_downstream_transposed_df[1:]\n",
    "t2ds_merged_downstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "t2ds_merged_downstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# pret2ds for distal promoters\n",
    "pret2ds_merged_downstream_df = merged_downstream_df[['gene_name'] + pret2ds_list] # [105 pret2ds]\n",
    "pret2ds_merged_downstream_transposed_df = pret2ds_merged_downstream_df.T\n",
    "pret2ds_merged_downstream_transposed_df.columns = pret2ds_merged_downstream_transposed_df.iloc[0]\n",
    "pret2ds_merged_downstream_transposed_df = pret2ds_merged_downstream_transposed_df[1:]\n",
    "pret2ds_merged_downstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "pret2ds_merged_downstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "# no_t2ds for distal promoters\n",
    "no_t2ds_merged_downstream_df = merged_downstream_df[['gene_name'] + no_t2ds_list] # [642 no_t2ds]\n",
    "no_t2ds_merged_downstream_transposed_df = no_t2ds_merged_downstream_df.T\n",
    "no_t2ds_merged_downstream_transposed_df.columns = no_t2ds_merged_downstream_transposed_df.iloc[0]\n",
    "no_t2ds_merged_downstream_transposed_df = no_t2ds_merged_downstream_transposed_df[1:]\n",
    "no_t2ds_merged_downstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "no_t2ds_merged_downstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "p_value_ks_t2ds_pret2ds_list = []\n",
    "p_value_ks_t2ds_no_t2ds_list = []\n",
    "p_value_ks_pret2ds_no_t2ds_list = []\n",
    "merged_downstream_col_name_list = list(t2ds_merged_downstream_transposed_df.columns)[1:]\n",
    "for col_name in merged_downstream_col_name_list:\n",
    "    t2ds_feature_list = list(t2ds_merged_downstream_transposed_df[col_name])\n",
    "    pret2ds_feature_list = list(pret2ds_merged_downstream_transposed_df[col_name])\n",
    "    no_t2ds_feature_list = list(no_t2ds_merged_downstream_transposed_df[col_name])\n",
    "    # [t2ds/ pret2ds]\n",
    "    ks_stat_t2ds_pret2ds, p_value_ks_t2ds_pret2ds = ks_2samp(t2ds_feature_list, pret2ds_feature_list)\n",
    "    p_value_ks_t2ds_pret2ds_list.append(p_value_ks_t2ds_pret2ds)\n",
    "    # print('[t2ds/ pret2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_pret2ds)\n",
    "    # [t2ds/ no_t2ds]\n",
    "    ks_stat_t2ds_no_t2ds, p_value_ks_t2ds_no_t2ds = ks_2samp(t2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_t2ds_no_t2ds_list.append(p_value_ks_t2ds_no_t2ds)\n",
    "    # print('[t2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_t2ds_no_t2ds)\n",
    "    # [pret2ds/ no_t2ds]\n",
    "    ks_stat_pret2ds_no_t2ds, p_value_ks_pret2ds_no_t2ds = ks_2samp(pret2ds_feature_list, no_t2ds_feature_list)\n",
    "    p_value_ks_pret2ds_no_t2ds_list.append(p_value_ks_pret2ds_no_t2ds)\n",
    "    # print('[pret2ds/ no_t2ds] Kolmogorov-Smirnov test p-value: ', p_value_ks_pret2ds_no_t2ds)\n",
    "\n",
    "merged_downstream_pvalue_df = pd.DataFrame({\n",
    "    'gene_names': merged_downstream_col_name_list,\n",
    "    't2ds_pret2ds_pvalue': p_value_ks_t2ds_pret2ds_list,\n",
    "    't2ds_no_t2ds_pvalue': p_value_ks_t2ds_no_t2ds_list,\n",
    "    'pret2ds_no_t2ds_pvalue': p_value_ks_pret2ds_no_t2ds_list\n",
    "})\n",
    "display(merged_downstream_pvalue_df)\n",
    "merged_downstream_pvalue_df.to_csv('./data/stat_data/merged_downstream_pvalue.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Knowledge Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = list(v1_label_phenodata_df.subject)\n",
    "print(subject_list)\n",
    "print('Number of subjects: ', len(subject_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build Up Graph Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert categorical feature into one-hot feature\n",
    "v1_label_phenodata_onehot_df = v1_label_phenodata_df.drop(columns =['id', 'fc', 'gpedid'])\n",
    "# One-hot encode the 'sex' column\n",
    "one_hot_encoded = pd.get_dummies(v1_label_phenodata_onehot_df['sex'], prefix='sex', dtype=int)\n",
    "v1_label_phenodata_onehot_df = v1_label_phenodata_onehot_df.drop(columns = ['sex'])\n",
    "# Concatenate the original DataFrame with the one-hot encoded column\n",
    "v1_label_phenodata_onehot_df = pd.concat([v1_label_phenodata_onehot_df, one_hot_encoded], axis=1)\n",
    "display(v1_label_phenodata_onehot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Categorize the feature into different levels by percentile\n",
    "# check the 5 and 95 percentiles of each feature\n",
    "feature_10percentile_list = []\n",
    "fearure_90percentile_list = []\n",
    "# features_to_remove = ['subject', 'sex']\n",
    "v1_label_phenodata_feature_list = list(v1_label_phenodata_df.columns)[4:]\n",
    "print('Number of numerical features: ', len(v1_label_phenodata_feature_list))\n",
    "# for loop each feature\n",
    "v1_label_phenodata_category_df = v1_label_phenodata_df.drop(columns =['id', 'fc', 'gpedid'])\n",
    "for feature in v1_label_phenodata_feature_list:\n",
    "    feature_value_array = np.array(v1_label_phenodata_df[feature])\n",
    "    feature_10percentile = np.percentile(feature_value_array, 10)\n",
    "    feature_10percentile_list.append(feature_10percentile)\n",
    "    feature_90percentile = np.percentile(feature_value_array, 90)\n",
    "    fearure_90percentile_list.append(feature_90percentile)\n",
    "    # print('---------- ' + str(feature) + ' ----------')\n",
    "    # print('--- 10 percentile of ' + str(feature), feature_10percentile)\n",
    "    # print('--- 90 percentile of ' + str(feature), feature_90percentile)\n",
    "    v1_label_phenodata_category_df[feature] = pd.cut(v1_label_phenodata_df[feature], bins=[float('-inf'), feature_10percentile, feature_90percentile, float('inf')], include_lowest=True, labels=[1,2,3])\n",
    "# convert 5 and 95 percentile of each feature into dataframe\n",
    "feature_percentile_df = pd.DataFrame({\n",
    "    'features': v1_label_phenodata_feature_list,\n",
    "    'feature_10percentile': feature_10percentile_list,\n",
    "    'feature_90percentile': fearure_90percentile_list\n",
    "})\n",
    "display(v1_label_phenodata_category_df)\n",
    "subfeature_list = []\n",
    "for feature in v1_label_phenodata_feature_list:\n",
    "    feature_unique_values = v1_label_phenodata_category_df[feature].nunique()\n",
    "    for number in np.arange(1, feature_unique_values+1):\n",
    "        feature_name = feature + '-' + str(number)\n",
    "        subfeature_list.append(feature_name)\n",
    "\n",
    "subfeature_node_idx_list = list(np.arange(len(subfeature_list)))\n",
    "subfeature_node_dict = {k:v for k, v in zip(subfeature_list, subfeature_node_idx_list)}\n",
    "subfeature_dict_df = pd.DataFrame({'subfeature_node_idx': subfeature_node_idx_list,\n",
    "                                'subfeature_names': subfeature_list})\n",
    "if os.path.exists('./data/filtered_data/') == False:\n",
    "    os.mkdir('./data/filtered_data/')\n",
    "subfeature_dict_df.to_csv('./data/filtered_data/subfeature_dict_df.csv', index=False, header=True)\n",
    "display(subfeature_dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create [node_idx and feature] map\n",
    "num_subfeature = subfeature_dict_df.shape[0]\n",
    "num_subject = v1_label_phenodata_category_df.shape[0]\n",
    "# Formalize the map between [node_idx] and [subject]\n",
    "subject_list = list(v1_label_phenodata_category_df.subject)\n",
    "subject_name_list = ['subject-' + str(subject) for subject in subject_list]\n",
    "subject_node_idx_list = list(np.arange(num_subfeature, num_subfeature+num_subject))\n",
    "# Formalize the subject dictionary\n",
    "subject_node_dict = {k:v for k, v in zip(subject_list, subject_node_idx_list)}\n",
    "subject_node_name_dict = {k:v for k, v in zip(subject_name_list, subject_node_idx_list)}\n",
    "subject_node_index_dict =  {k:v for k, v in zip(subject_node_idx_list, subject_name_list)}\n",
    "subject_dict_df = pd.DataFrame({'subject_node_idx': subject_node_idx_list,\n",
    "                            'subject_number': subject_list,\n",
    "                            'subject_name': subject_name_list})\n",
    "print(subject_node_dict)\n",
    "display(subject_dict_df)\n",
    "subject_dict_df.to_csv('./data/filtered_data/subject_dict_df.csv', index=False, header=True)\n",
    "\n",
    "# Concatenate [subfeature_dict_df] and [subject_dict_df]\n",
    "subject_number_dict_df = subject_dict_df.drop(columns=['subject_number'])\n",
    "subject_number_dict_df = subject_number_dict_df.rename(columns={'subject_node_idx': 'node_idx',\n",
    "                                                            'subject_name': 'node_name'})\n",
    "subfeature_dict_df = subfeature_dict_df.rename(columns={'subfeature_node_idx': 'node_idx',\n",
    "                                                            'subfeature_names': 'node_name'})\n",
    "node_idx_name_map_df = pd.concat([subfeature_dict_df, subject_number_dict_df])\n",
    "node_idx_name_map_df = node_idx_name_map_df.reset_index(drop=True)\n",
    "display(node_idx_name_map_df)\n",
    "node_idx_name_map_df.to_csv('./data/filtered_data/node_idx_name_map_df.csv', index=False, header=True)\n",
    "node_name_idx_dict = node_idx_name_map_df.set_index('node_name')['node_idx'].to_dict()\n",
    "print(node_name_idx_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formalize the subject and subfeature into the graph\n",
    "# Convert [intersected_v1_label_phenodata_category_df] into [node_idx] dataframe\n",
    "v1_label_phenodata_category_name_df = v1_label_phenodata_category_df.copy()\n",
    "for feature in v1_label_phenodata_feature_list:\n",
    "    v1_label_phenodata_category_name_df[feature] = feature + '-' + v1_label_phenodata_category_df[feature].astype(int).astype(str)\n",
    "v1_label_phenodata_category_name_df['subject'] = 'subject-' + v1_label_phenodata_category_df['subject'].astype(int).astype(str)\n",
    "v1_label_phenodata_category_num_df = v1_label_phenodata_category_name_df.copy()\n",
    "v1_label_phenodata_category_num_df = v1_label_phenodata_category_num_df.replace(node_name_idx_dict)\n",
    "display(v1_label_phenodata_category_num_df)\n",
    "\n",
    "# Build up features internal relationship\n",
    "subfeature_from_list = []\n",
    "subfeature_to_list = []\n",
    "v1_label_phenodata_feature_list.remove('sex')\n",
    "for feature in v1_label_phenodata_feature_list: # [v1_label_phenodata_feature_list] (without [sex / subject])\n",
    "    feature_unique_values = v1_label_phenodata_category_df[feature].nunique()\n",
    "    for number in np.arange(1, feature_unique_values):\n",
    "        feature_from_name = feature + '-' + str(number)\n",
    "        feature_to_name = feature + '-' + str(number+1)\n",
    "        subfeature_from_list.append(feature_from_name)\n",
    "        subfeature_to_list.append(feature_to_name)\n",
    "subfeature_name_edge_df = pd.DataFrame({'subfeature_from_node_idx': subfeature_from_list,\n",
    "                                    'subfeature_to_node_idx': subfeature_to_list})\n",
    "subfeature_num_edge_df = subfeature_name_edge_df.replace(node_name_idx_dict)\n",
    "subfeature_num_edge_df = subfeature_num_edge_df.rename(columns={'subfeature_from_node_idx': 'from_node_idx',\n",
    "                                                            'subfeature_to_node_idx': 'to_node_idx'})\n",
    "\n",
    "# display(subfeature_num_edge_df)                \n",
    "\n",
    "# Convert the number into the [edge_index]\n",
    "v1_label_phenodata_category_num_columns = list(v1_label_phenodata_category_num_df.columns)[1:] \n",
    "v1_label_phenodata_category_num_columns.remove('sex') # remove [sex]\n",
    "display(v1_label_phenodata_category_num_df)\n",
    "print(v1_label_phenodata_category_num_columns)\n",
    "v1_label_phenodata_category_num_dflist = []\n",
    "for column_name in v1_label_phenodata_category_num_columns:\n",
    "    subject_nodeidx = list(v1_label_phenodata_category_num_df['subject'])\n",
    "    subfeature_idx = list(v1_label_phenodata_category_num_df[column_name].astype(int))\n",
    "    tmp_df = pd.DataFrame({'subject_node_idx': subject_nodeidx, \n",
    "                            'subfeature_idx': subfeature_idx})\n",
    "    v1_label_phenodata_category_num_dflist.append(tmp_df)\n",
    "v1_label_phenodata_category_edge_df = pd.concat(v1_label_phenodata_category_num_dflist)\n",
    "# display(intersected_v1_label_phenodata_category_edge_df)\n",
    "v1_label_phenodata_category_edge_df = v1_label_phenodata_category_edge_df.rename(columns={'subject_node_idx': 'from_node_idx',\n",
    "                                                                                                                'subfeature_idx': 'to_node_idx'})\n",
    "num_edge_df = pd.concat([subfeature_num_edge_df, v1_label_phenodata_category_edge_df])\n",
    "display(num_edge_df)\n",
    "num_edge_df.to_csv('./data/filtered_data/num_edge_df.csv', index=False, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Parse Clinical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(v1_label_phenodata_onehot_df)\n",
    "v1_label_phenodata_onehot_nodeidx_df = v1_label_phenodata_onehot_df.copy()\n",
    "#pd.set_option('future.no_silent_downcasting', True)\n",
    "v1_label_phenodata_onehot_nodeidx_df['subject'] = v1_label_phenodata_onehot_nodeidx_df['subject'].replace(subject_node_dict)\n",
    "display(v1_label_phenodata_onehot_nodeidx_df)\n",
    "v1_label_phenodata_onehot_nodeidx_df.to_csv('./data/filtered_data/v1_label_phenodata_onehot_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Parse Transcriptomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(merged_tran_v1_df)\n",
    "merged_tran_v1_transposed_df = merged_tran_v1_df.T\n",
    "merged_tran_v1_transposed_df.columns = merged_tran_v1_transposed_df.iloc[0]\n",
    "merged_tran_v1_transposed_df = merged_tran_v1_transposed_df[1:] \n",
    "# convert index to first column with the name 'subject' and remove the index name\n",
    "merged_tran_v1_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_tran_v1_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_tran_v1_nodeidx_df = merged_tran_v1_transposed_df.copy()\n",
    "merged_tran_v1_nodeidx_df['subject'] = merged_tran_v1_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_tran_v1_nodeidx_df = merged_tran_v1_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "display(merged_tran_v1_nodeidx_df)\n",
    "merged_tran_v1_nodeidx_df.to_csv('./data/filtered_data/merged_tran_v1_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Parse Epigenomics Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core promoter\n",
    "merged_core_promoter_transposed_df = merged_core_promoter_df.T\n",
    "merged_core_promoter_transposed_df.columns = merged_core_promoter_transposed_df.iloc[0]\n",
    "merged_core_promoter_transposed_df = merged_core_promoter_transposed_df[1:] \n",
    "# Convert index to first column with the name 'subject' and remove the index name\n",
    "merged_core_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_core_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_core_promoter_nodeidx_df = merged_core_promoter_transposed_df.copy()\n",
    "merged_core_promoter_nodeidx_df['subject'] = merged_core_promoter_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_core_promoter_nodeidx_df = merged_core_promoter_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "merged_core_promoter_nodeidx_df.to_csv('./data/filtered_data/merged_core_promoter_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proximal promoter\n",
    "merged_proximal_promoter_transposed_df = merged_proximal_promoter_df.T\n",
    "merged_proximal_promoter_transposed_df.columns = merged_proximal_promoter_transposed_df.iloc[0]\n",
    "merged_proximal_promoter_transposed_df = merged_proximal_promoter_transposed_df[1:] \n",
    "# Convert index to first column with the name 'subject' and remove the index name\n",
    "merged_proximal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_proximal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_proximal_promoter_nodeidx_df = merged_proximal_promoter_transposed_df.copy()\n",
    "merged_proximal_promoter_nodeidx_df['subject'] = merged_proximal_promoter_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_proximal_promoter_nodeidx_df = merged_proximal_promoter_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "merged_proximal_promoter_nodeidx_df.to_csv('./data/filtered_data/merged_proximal_promoter_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distal promoter\n",
    "merged_distal_promoter_transposed_df = merged_distal_promoter_df.T\n",
    "merged_distal_promoter_transposed_df.columns = merged_distal_promoter_transposed_df.iloc[0]\n",
    "merged_distal_promoter_transposed_df = merged_distal_promoter_transposed_df[1:] \n",
    "# Convert index to first column with the name 'subject' and remove the index name\n",
    "merged_distal_promoter_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_distal_promoter_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_distal_promoter_nodeidx_df = merged_distal_promoter_transposed_df.copy()\n",
    "merged_distal_promoter_nodeidx_df['subject'] = merged_distal_promoter_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_distal_promoter_nodeidx_df = merged_distal_promoter_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "merged_distal_promoter_nodeidx_df.to_csv('./data/filtered_data/merged_distal_promoter_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upstream\n",
    "merged_upstream_transposed_df = merged_upstream_df.T\n",
    "merged_upstream_transposed_df.columns = merged_upstream_transposed_df.iloc[0]\n",
    "merged_upstream_transposed_df = merged_upstream_transposed_df[1:] \n",
    "# Convert index to first column with the name 'subject' and remove the index name\n",
    "merged_upstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_upstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_upstream_nodeidx_df = merged_upstream_transposed_df.copy()\n",
    "merged_upstream_nodeidx_df['subject'] = merged_upstream_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_upstream_nodeidx_df = merged_upstream_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "merged_upstream_nodeidx_df.to_csv('./data/filtered_data/merged_upstream_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downstream\n",
    "merged_downstream_transposed_df = merged_downstream_df.T\n",
    "merged_downstream_transposed_df.columns = merged_downstream_transposed_df.iloc[0]\n",
    "merged_downstream_transposed_df = merged_downstream_transposed_df[1:] \n",
    "# Convert index to first column with the name 'subject' and remove the index name\n",
    "merged_downstream_transposed_df.reset_index(level=0, inplace=True)\n",
    "merged_downstream_transposed_df.rename(columns={'index': 'subject'}, inplace=True)\n",
    "merged_downstream_nodeidx_df = merged_downstream_transposed_df.copy()\n",
    "merged_downstream_nodeidx_df['subject'] = merged_downstream_transposed_df['subject'].replace(subject_node_dict)\n",
    "merged_downstream_nodeidx_df = merged_downstream_nodeidx_df.rename(columns={'subject': 'subject_nodeidx'})\n",
    "merged_downstream_nodeidx_df.to_csv('./data/filtered_data/merged_downstream_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Intersected Nodes in Gene Regulatory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formalize the gene node\n",
    "gene_name_list = list(merged_tran_v1_df.gene_name)\n",
    "gene_node_idx_list = list(np.arange(0, len(gene_name_list)))\n",
    "gene_num_dict = {k:v for k, v in zip(gene_node_idx_list, gene_name_list)}\n",
    "gene_name_dict = {k:v for k, v in zip(gene_name_list, gene_node_idx_list)}\n",
    "gene_num_dict_df = pd.DataFrame({'gene_node_idx': gene_node_idx_list,\n",
    "                                 'gene_node_name': gene_name_list})\n",
    "display(gene_num_dict_df)\n",
    "gene_num_dict_df.to_csv('./data/filtered_data/gene_num_dict_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter gene in the [merged_tran_v1_df]\n",
    "if selected_database == 'KEGG':\n",
    "    up_kegg_df = pd.read_csv('./data/kg_data/KEGG/up_kegg.csv')\n",
    "    up_kegg_df = up_kegg_df.sort_values(by=['src', 'dest'])\n",
    "    up_kegg_df = up_kegg_df[up_kegg_df['src'].isin(gene_name_list)]\n",
    "    up_kegg_df = up_kegg_df[up_kegg_df['dest'].isin(gene_name_list)]\n",
    "    up_kegg_df = up_kegg_df.reset_index(drop=True)\n",
    "    # Check the number of genes in the [up_kegg_df]\n",
    "    up_kegg_src_list = list(up_kegg_df.src)\n",
    "    up_kegg_dest_list = list(up_kegg_df.dest)\n",
    "    up_kegg_gene_list = list(set(up_kegg_src_list + up_kegg_dest_list))\n",
    "    print('Number of genes in the [up_kegg_df]: ', len(up_kegg_gene_list))\n",
    "    # Replace the gene name in the [up_kegg_df] with the node index\n",
    "    up_kegg_df = up_kegg_df.replace({'src': gene_name_dict, 'dest': gene_name_dict})\n",
    "    up_kegg_df = up_kegg_df.rename(columns={'src': 'From', 'dest': 'To'})\n",
    "    up_kegg_df.to_csv('./data/filtered_data/gene_num_edge_df.csv', index=False, header=True)\n",
    "\n",
    "    reverse_up_kegg_df = up_kegg_df[['To', 'From']]\n",
    "    reverse_up_kegg_df = reverse_up_kegg_df.rename(columns={'To': 'From', 'From': 'To'})\n",
    "    concat_df = pd.concat([up_kegg_df, reverse_up_kegg_df], axis=0)\n",
    "    reverse_gene_num_edge_df = concat_df.sort_values(by=['From', 'To']).drop_duplicates().reset_index(drop=True)\n",
    "    reverse_gene_num_edge_df.to_csv('./data/filtered_data/reverse_gene_num_edge_df.csv', index=False, header=True)\n",
    "    display(reverse_gene_num_edge_df)\n",
    "if selected_database == 'BioGRID':\n",
    "    up_biogrid_df = pd.read_csv('./data/kg_data/BioGRID/up_biogrid.csv')\n",
    "    up_biogrid_df = up_biogrid_df.sort_values(by=['src', 'dest'])\n",
    "    up_biogrid_df = up_biogrid_df[up_biogrid_df['src'].isin(gene_name_list)]\n",
    "    up_biogrid_df = up_biogrid_df[up_biogrid_df['dest'].isin(gene_name_list)]\n",
    "    up_biogrid_df = up_biogrid_df.reset_index(drop=True)\n",
    "    # Check the number of genes in the [up_biogrid_df]\n",
    "    up_biogrid_src_list = list(up_biogrid_df.src)\n",
    "    up_biogrid_dest_list = list(up_biogrid_df.dest)\n",
    "    up_biogrid_gene_list = list(set(up_biogrid_src_list + up_biogrid_dest_list))\n",
    "    print('Number of genes in the [up_biogrid_df]: ', len(up_biogrid_gene_list))\n",
    "    # Replace the gene name in the [up_biogrid_df] with the node index\n",
    "    up_biogrid_df = up_biogrid_df.replace({'src': gene_name_dict, 'dest': gene_name_dict})\n",
    "    up_biogrid_df = up_biogrid_df.rename(columns={'src': 'From', 'dest': 'To'})\n",
    "    up_biogrid_df.to_csv('./data/filtered_data/gene_num_edge_df.csv', index=False, header=True)\n",
    "\n",
    "    reverse_up_biogrid_df = up_biogrid_df[['To', 'From']]\n",
    "    reverse_up_biogrid_df = reverse_up_biogrid_df.rename(columns={'To': 'From', 'From': 'To'})\n",
    "    concat_df = pd.concat([up_biogrid_df, reverse_up_biogrid_df], axis=0)\n",
    "    reverse_gene_num_edge_df = concat_df.sort_values(by=['From', 'To']).drop_duplicates().reset_index(drop=True)\n",
    "    reverse_gene_num_edge_df.to_csv('./data/filtered_data/reverse_gene_num_edge_df.csv', index=False, header=True)\n",
    "    display(reverse_gene_num_edge_df)\n",
    "if selected_database == 'STRING':\n",
    "    up_string_df = pd.read_csv('./data/kg_data/STRING/up_string.csv')\n",
    "    up_string_df = up_string_df.sort_values(by=['src', 'dest'])\n",
    "    up_string_df = up_string_df[up_string_df['src'].isin(gene_name_list)]\n",
    "    up_string_df = up_string_df[up_string_df['dest'].isin(gene_name_list)]\n",
    "    up_string_df = up_string_df.reset_index(drop=True)\n",
    "    # Check the number of genes in the [up_string_df]\n",
    "    up_string_src_list = list(up_string_df.src)\n",
    "    up_string_dest_list = list(up_string_df.dest)\n",
    "    up_string_gene_list = list(set(up_string_src_list + up_string_dest_list))\n",
    "    print('Number of genes in the [up_string_df]: ', len(up_string_gene_list))\n",
    "    # Replace the gene name in the [up_string_df] with the node index\n",
    "    up_string_df = up_string_df.replace({'src': gene_name_dict, 'dest': gene_name_dict})\n",
    "    up_string_df = up_string_df.rename(columns={'src': 'From', 'dest': 'To'})\n",
    "    up_string_df.to_csv('./data/filtered_data/gene_num_edge_df.csv', index=False, header=True)\n",
    "\n",
    "    reverse_up_string_df = up_string_df[['To', 'From']]\n",
    "    reverse_up_string_df = reverse_up_string_df.rename(columns={'To': 'From', 'From': 'To'})\n",
    "    concat_df = pd.concat([up_string_df, reverse_up_string_df], axis=0)\n",
    "    reverse_gene_num_edge_df = concat_df.sort_values(by=['From', 'To']).drop_duplicates().reset_index(drop=True)\n",
    "    reverse_gene_num_edge_df.to_csv('./data/filtered_data/reverse_gene_num_edge_df.csv', index=False, header=True)\n",
    "    display(reverse_gene_num_edge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Formalize Gene Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "if os.path.exists('./data/post_data/') == False:\n",
    "    os.mkdir('./data/post_data/')\n",
    "\n",
    "\n",
    "### Convert the [merged_tran_v1_nodeidx_df] to numpy array as [gene_tran_x]\n",
    "print('--------------- Gene Transcriptomics ---------------')\n",
    "merged_tran_v1_nodeidx_numpy_df = merged_tran_v1_nodeidx_df.copy()\n",
    "merged_tran_v1_nodeidx_numpy_df = merged_tran_v1_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_tran_x_df = merged_tran_v1_nodeidx_numpy_df.copy()\n",
    "gene_tran_x = merged_tran_v1_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Transcriptomics X Features -----')\n",
    "print(gene_tran_x.shape)\n",
    "np.save('./data/post_data/gene_tran_x.npy', gene_tran_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_tran_x_df = pd.DataFrame()\n",
    "for col in gene_tran_x_df.columns:\n",
    "    if gene_tran_x_df[col].max() == gene_tran_x_df[col].min():\n",
    "        norm_gene_tran_x_df[col] = gene_tran_x_df[col]\n",
    "    else:\n",
    "        norm_gene_tran_x_df[col] = (gene_tran_x_df[col] - gene_tran_x_df[col].min()) / (gene_tran_x_df[col].max() - gene_tran_x_df[col].min())\n",
    "norm_gene_tran_x = norm_gene_tran_x_df.to_numpy()\n",
    "print('----- Gene Norm Transcriptomics X Features -----')\n",
    "print(norm_gene_tran_x.shape)\n",
    "np.save('./data/post_data/norm_gene_tran_x.npy', norm_gene_tran_x)\n",
    "\n",
    "\n",
    "### Convert the [merged_core_promoter_nodeidx_df] to numpy array as [gene_core_promoter_x]\n",
    "print('--------------- Gene Core Promoter ---------------')\n",
    "merged_core_promoter_nodeidx_numpy_df = merged_core_promoter_nodeidx_df.copy()\n",
    "merged_core_promoter_nodeidx_numpy_df = merged_core_promoter_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_core_promoter_x_df = merged_core_promoter_nodeidx_numpy_df.copy()\n",
    "gene_core_promoter_x = merged_core_promoter_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Core Promoter X Features -----')\n",
    "print(gene_core_promoter_x.shape)\n",
    "np.save('./data/post_data/gene_core_promoter_x.npy', gene_core_promoter_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_core_promoter_x_df = pd.DataFrame()\n",
    "for col in gene_core_promoter_x_df.columns:\n",
    "    if gene_core_promoter_x_df[col].max() == gene_core_promoter_x_df[col].min():\n",
    "        norm_gene_core_promoter_x_df[col] = gene_core_promoter_x_df[col]\n",
    "    else:\n",
    "        norm_gene_core_promoter_x_df[col] = (gene_core_promoter_x_df[col] - gene_core_promoter_x_df[col].min()) / (gene_core_promoter_x_df[col].max() - gene_core_promoter_x_df[col].min())\n",
    "norm_gene_core_promoter_x = norm_gene_core_promoter_x_df.to_numpy()\n",
    "print('----- Gene Norm Core Promoter X Features -----')\n",
    "print(norm_gene_core_promoter_x.shape)\n",
    "np.save('./data/post_data/norm_gene_core_promoter_x.npy', norm_gene_core_promoter_x)\n",
    "\n",
    "\n",
    "### Convert the [merged_proximal_promoter_nodeidx_df] to numpy array as [gene_proximal_promoter_x]\n",
    "print('--------------- Gene Proximal Promoter ---------------')\n",
    "merged_proximal_promoter_nodeidx_numpy_df = merged_proximal_promoter_nodeidx_df.copy()\n",
    "merged_proximal_promoter_nodeidx_numpy_df = merged_proximal_promoter_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_proximal_promoter_x_df = merged_proximal_promoter_nodeidx_numpy_df.copy()\n",
    "gene_proximal_promoter_x = merged_proximal_promoter_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Proximal Promoter X Features -----')\n",
    "print(gene_proximal_promoter_x.shape)\n",
    "np.save('./data/post_data/gene_proximal_promoter_x.npy', gene_proximal_promoter_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_proximal_promoter_x_df = pd.DataFrame()\n",
    "for col in gene_proximal_promoter_x_df.columns:\n",
    "    if gene_proximal_promoter_x_df[col].max() == gene_proximal_promoter_x_df[col].min():\n",
    "        norm_gene_proximal_promoter_x_df[col] = gene_proximal_promoter_x_df[col]\n",
    "    else:\n",
    "        norm_gene_proximal_promoter_x_df[col] = (gene_proximal_promoter_x_df[col] - gene_proximal_promoter_x_df[col].min()) / (gene_proximal_promoter_x_df[col].max() - gene_proximal_promoter_x_df[col].min())\n",
    "norm_gene_proximal_promoter_x = norm_gene_proximal_promoter_x_df.to_numpy()\n",
    "print('----- Gene Norm Proximal Promoter X Features -----')\n",
    "print(norm_gene_proximal_promoter_x.shape)\n",
    "np.save('./data/post_data/norm_gene_proximal_promoter_x.npy', norm_gene_proximal_promoter_x)\n",
    "\n",
    "\n",
    "### Convert the [merged_distal_promoter_nodeidx_df] to numpy array as [gene_distal_promoter_x]\n",
    "print('--------------- Gene Distal Promoter ---------------')\n",
    "merged_distal_promoter_nodeidx_numpy_df = merged_distal_promoter_nodeidx_df.copy()\n",
    "merged_distal_promoter_nodeidx_numpy_df = merged_distal_promoter_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_distal_promoter_x_df = merged_distal_promoter_nodeidx_numpy_df.copy()\n",
    "gene_distal_promoter_x = merged_distal_promoter_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Distal Promoter X Features -----')\n",
    "print(gene_distal_promoter_x.shape)\n",
    "np.save('./data/post_data/gene_distal_promoter_x.npy', gene_distal_promoter_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_distal_promoter_x_df = pd.DataFrame()\n",
    "for col in gene_distal_promoter_x_df.columns:\n",
    "    if gene_distal_promoter_x_df[col].max() == gene_distal_promoter_x_df[col].min():\n",
    "        norm_gene_distal_promoter_x_df[col] = gene_distal_promoter_x_df[col]\n",
    "    else:\n",
    "        norm_gene_distal_promoter_x_df[col] = (gene_distal_promoter_x_df[col] - gene_distal_promoter_x_df[col].min()) / (gene_distal_promoter_x_df[col].max() - gene_distal_promoter_x_df[col].min())\n",
    "norm_gene_distal_promoter_x = norm_gene_distal_promoter_x_df.to_numpy()\n",
    "print('----- Gene Norm Distal Promoter X Features -----')\n",
    "print(norm_gene_distal_promoter_x.shape)\n",
    "np.save('./data/post_data/norm_gene_distal_promoter_x.npy', norm_gene_distal_promoter_x)\n",
    "\n",
    "\n",
    "### Convert the [merged_upstream_nodeidx_df] to numpy array as [gene_upstream_x]\n",
    "print('--------------- Gene Upstream ---------------')\n",
    "merged_upstream_nodeidx_numpy_df = merged_upstream_nodeidx_df.copy()\n",
    "merged_upstream_nodeidx_numpy_df = merged_upstream_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_upstream_x_df = merged_upstream_nodeidx_numpy_df.copy()\n",
    "gene_upstream_x = merged_upstream_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Upstream X Features -----')\n",
    "print(gene_upstream_x.shape)\n",
    "np.save('./data/post_data/gene_upstream_x.npy', gene_upstream_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_upstream_x_df = pd.DataFrame()\n",
    "for col in gene_upstream_x_df.columns:\n",
    "    if gene_upstream_x_df[col].max() == gene_upstream_x_df[col].min():\n",
    "        norm_gene_upstream_x_df[col] = gene_upstream_x_df[col]\n",
    "    else:\n",
    "        norm_gene_upstream_x_df[col] = (gene_upstream_x_df[col] - gene_upstream_x_df[col].min()) / (gene_upstream_x_df[col].max() - gene_upstream_x_df[col].min())\n",
    "norm_gene_upstream_x = norm_gene_upstream_x_df.to_numpy()\n",
    "print('----- Gene Norm Upstream X Features -----')\n",
    "print(norm_gene_upstream_x.shape)\n",
    "np.save('./data/post_data/norm_gene_upstream_x.npy', norm_gene_upstream_x)\n",
    "\n",
    "\n",
    "### Convert the [merged_downstream_nodeidx_df] to numpy array as [gene_downstream_x]\n",
    "print('--------------- Gene Downstream ---------------')\n",
    "merged_downstream_nodeidx_numpy_df = merged_downstream_nodeidx_df.copy()\n",
    "merged_downstream_nodeidx_numpy_df = merged_downstream_nodeidx_numpy_df.drop(columns='subject_nodeidx')\n",
    "gene_downstream_x_df = merged_downstream_nodeidx_numpy_df.copy()\n",
    "gene_downstream_x = merged_downstream_nodeidx_numpy_df.to_numpy()\n",
    "print('----- Gene Downstream X Features -----')\n",
    "print(gene_downstream_x.shape)\n",
    "np.save('./data/post_data/gene_downstream_x.npy', gene_downstream_x)\n",
    "# Suppress the PerformanceWarning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_gene_downstream_x_df = pd.DataFrame()\n",
    "for col in gene_downstream_x_df.columns:\n",
    "    if gene_downstream_x_df[col].max() == gene_downstream_x_df[col].min():\n",
    "        norm_gene_downstream_x_df[col] = gene_downstream_x_df[col]\n",
    "    else:\n",
    "        norm_gene_downstream_x_df[col] = (gene_downstream_x_df[col] - gene_downstream_x_df[col].min()) / (gene_downstream_x_df[col].max() - gene_downstream_x_df[col].min())\n",
    "norm_gene_downstream_x = norm_gene_downstream_x_df.to_numpy()\n",
    "print('----- Gene Norm Downstream X Features -----')\n",
    "print(norm_gene_downstream_x.shape)\n",
    "np.save('./data/post_data/norm_gene_downstream_x.npy', norm_gene_downstream_x)\n",
    "\n",
    "\n",
    "### Concatenate [gene_tran_x] + [gene_core_promoter_x] + [gene_proximal_promoter_x] + [gene_distal_promoter_x] + [gene_upstream_x] + [gene_downstream_x]\n",
    "print('--------------- Concatenate Gene Features ---------------')\n",
    "gene_x = np.concatenate((gene_tran_x, gene_core_promoter_x, gene_proximal_promoter_x, gene_distal_promoter_x, gene_upstream_x, gene_downstream_x), axis=1)\n",
    "print('----- Concatenate Gene Features -----')\n",
    "print(gene_x.shape)\n",
    "np.save('./data/post_data/gene_x.npy', gene_x)\n",
    "\n",
    "\n",
    "### Concatenate [norm_gene_tran_x] + [norm_gene_core_promoter_x] + [norm_gene_proximal_promoter_x] + [norm_gene_distal_promoter_x] + [norm_gene_upstream_x] + [norm_gene_downstream_x]\n",
    "print('--------------- Concatenate Gene Features ---------------')\n",
    "norm_gene_x = np.concatenate((norm_gene_tran_x, norm_gene_core_promoter_x, norm_gene_proximal_promoter_x, norm_gene_distal_promoter_x, norm_gene_upstream_x, norm_gene_downstream_x), axis=1)\n",
    "print('----- Concatenate Gene Features -----')\n",
    "print(norm_gene_x.shape)\n",
    "np.save('./data/post_data/norm_gene_x.npy', norm_gene_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Formalize Gene Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the [gene_num_edge_df] to numpy array as [gene_edge_index]\n",
    "if selected_database =='KEGG':\n",
    "    gene_edge_index = up_kegg_df.to_numpy().T\n",
    "if selected_database =='BioGRID':\n",
    "    gene_edge_index = up_biogrid_df.to_numpy().T\n",
    "if selected_database =='STRING':\n",
    "    gene_edge_index = up_string_df.to_numpy().T\n",
    "print('----- Gene Edge Index -----')\n",
    "print(gene_edge_index.shape)\n",
    "print(gene_edge_index)\n",
    "np.save('./data/post_data/gene_edge_index.npy', gene_edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 Formalize Key Genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the t6_common_genes with corresponding gene index by [filtered_data/gene_num_dict_df.csv]\n",
    "t6_common_genes = sorted(list(t6_common_genes))\n",
    "print('Number of common genes: ', len(t6_common_genes))\n",
    "print(t6_common_genes)\n",
    "t6_common_genes_idx = []\n",
    "for gene in t6_common_genes:\n",
    "    t6_common_genes_idx.append(gene_name_dict[gene])\n",
    "print('Number of common genes: ', len(t6_common_genes_idx))\n",
    "print(t6_common_genes_idx)\n",
    "\n",
    "# Convert the [t6_common_genes_idx] to numpy array as [t6_common_genes_idx]\n",
    "t6_common_genes_idx = np.array(t6_common_genes_idx)\n",
    "np.save('./data/post_data/key_gene_idx.npy', t6_common_genes_idx)\n",
    "\n",
    "# save key gene names and index as csv file\n",
    "key_gene_df = pd.DataFrame({\n",
    "    'gene_node_idx': t6_common_genes_idx,\n",
    "    'gene_name': t6_common_genes\n",
    "})\n",
    "key_gene_df.to_csv('./data/filtered_data/key_gene_df.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.8 Formalize Patient Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [x, edge_index]\n",
    "# [x] = [subfeature_phenodata_x] + [subject_phenodata_x]\n",
    "if os.path.exists('./data/post_data/') == False:\n",
    "    os.mkdir('./data/post_data/')\n",
    "# display(v1_label_phenodata_onehot_nodeidx_df)\n",
    "x_v1_label_phenodata_onehot_nodeidx_df = v1_label_phenodata_onehot_nodeidx_df.drop(columns=['subject'])\n",
    "# display(x_v1_label_phenodata_onehot_nodeidx_df)\n",
    "subject_phenodata_x = x_v1_label_phenodata_onehot_nodeidx_df.to_numpy()\n",
    "subfeature_dict_df = pd.read_csv('./data/filtered_data/subfeature_dict_df.csv')\n",
    "num_subfeature = subfeature_dict_df.shape[0]\n",
    "num_feature = x_v1_label_phenodata_onehot_nodeidx_df.shape[1]\n",
    "subfeature_phenodata_x = np.zeros((num_subfeature, num_feature))\n",
    "x = np.vstack((subfeature_phenodata_x, subject_phenodata_x))\n",
    "print('----- X Shape -----')\n",
    "print(x.shape)\n",
    "np.save('./data/post_data/x.npy', x)\n",
    "\n",
    "# [norm_x] = [subfeature_phenodata_x] + [norm_subject_phenodata_x]\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "norm_subject_phenodata_x_df = pd.DataFrame()\n",
    "for col in x_v1_label_phenodata_onehot_nodeidx_df.columns:\n",
    "    if x_v1_label_phenodata_onehot_nodeidx_df[col].max() == x_v1_label_phenodata_onehot_nodeidx_df[col].min():\n",
    "        norm_subject_phenodata_x_df[col] = x_v1_label_phenodata_onehot_nodeidx_df[col]\n",
    "    else:\n",
    "        norm_subject_phenodata_x_df[col] = (x_v1_label_phenodata_onehot_nodeidx_df[col] - x_v1_label_phenodata_onehot_nodeidx_df[col].min()) / (x_v1_label_phenodata_onehot_nodeidx_df[col].max() - x_v1_label_phenodata_onehot_nodeidx_df[col].min())\n",
    "norm_subject_phenodata_x = norm_subject_phenodata_x_df.to_numpy()\n",
    "norm_subfeature_phenodata_x = np.zeros((num_subfeature, num_feature))\n",
    "norm_x = np.vstack((norm_subfeature_phenodata_x, norm_subject_phenodata_x))\n",
    "print('----- Norm X Shape -----')\n",
    "print(norm_x.shape)\n",
    "np.save('./data/post_data/norm_x.npy', norm_x)\n",
    "\n",
    "# [edge_index]\n",
    "num_edge_df = pd.read_csv('./data/filtered_data/num_edge_df.csv')\n",
    "display(num_edge_df)\n",
    "edge_index = np.transpose(num_edge_df.to_numpy())\n",
    "np.save('./data/post_data/edge_index.npy', edge_index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.9 Formalize Patient Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(subject_list))\n",
    "t2ds_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [label]\n",
    "### filter out different labels\n",
    "t2ds_df = t2ds_label_df[t2ds_label_df['t2ds'] == 1]['subject']\n",
    "t2ds_df = t2ds_df.reset_index(drop=True).to_frame()\n",
    "t2ds_df.columns = ['subject']\n",
    "t2ds_df['t2ds'] = t2ds_df.shape[0] * [1]\n",
    "t2ds_df['pret2ds'] = t2ds_df.shape[0] * [0]\n",
    "t2ds_df['no_t2ds'] = t2ds_df.shape[0] * [0]\n",
    "# display(t2ds_df)\n",
    "pret2ds_df = t2ds_label_df[t2ds_label_df['pret2ds'] == 1]['subject']\n",
    "pret2ds_df = pret2ds_df.reset_index(drop=True).to_frame()\n",
    "pret2ds_df.columns = ['subject']\n",
    "pret2ds_df['t2ds'] = pret2ds_df.shape[0] * [0]\n",
    "pret2ds_df['pret2ds'] = pret2ds_df.shape[0] * [1]\n",
    "pret2ds_df['no_t2ds'] = pret2ds_df.shape[0] * [0]\n",
    "# display(pret2ds_df)\n",
    "no_t2ds_df = t2ds_label_df[(t2ds_label_df['t2ds'] != 1 ) & (t2ds_label_df['pret2ds'] != 1)]['subject']\n",
    "no_t2ds_df = no_t2ds_df.reset_index(drop=True).to_frame()\n",
    "no_t2ds_df.columns = ['subject']\n",
    "no_t2ds_df['t2ds'] = no_t2ds_df.shape[0] * [0]\n",
    "no_t2ds_df['pret2ds'] = no_t2ds_df.shape[0] * [0]\n",
    "no_t2ds_df['no_t2ds'] = no_t2ds_df.shape[0] * [1]\n",
    "# display(no_t2ds_df)\n",
    "label_phenodata_onehot_df = pd.concat([t2ds_df, pret2ds_df, no_t2ds_df])\n",
    "node_idx_name_map_df = pd.read_csv('./data/filtered_data/node_idx_name_map_df.csv')\n",
    "label_phenodata_onehot_df['subject'] = 'subject-' + label_phenodata_onehot_df['subject'].astype(str)\n",
    "# display(label_phenodata_onehot_df)\n",
    "label_phenodata_onehot_nodeidx_df = label_phenodata_onehot_df.merge(node_idx_name_map_df, left_on='subject', right_on='node_name')\n",
    "label_phenodata_onehot_nodeidx_df = label_phenodata_onehot_nodeidx_df[['node_idx', 't2ds', 'pret2ds', 'no_t2ds']].sort_values(by=['node_idx']).reset_index(drop=True)\n",
    "display(label_phenodata_onehot_nodeidx_df)\n",
    "label_phenodata_onehot_nodeidx_df.to_csv('./data/filtered_data/label_phenodata_onehot_nodeidx_df.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build Up Common GNN Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Formalize Phenotype x Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_x_df = v1_label_phenodata_onehot_df.drop(columns=['subject'])\n",
    "display(pheno_x_df)\n",
    "\n",
    "pheno_x = pheno_x_df.to_numpy()\n",
    "print('----- Pheno X Features -----')\n",
    "print(pheno_x.shape)\n",
    "print(pheno_x)\n",
    "np.save('./data/post_data/pheno_x.npy', pheno_x) \n",
    "\n",
    "# Compute the norm for each combination of columns\n",
    "norm_pheno_x_df = pd.DataFrame()\n",
    "for col in pheno_x_df.columns:\n",
    "    norm_pheno_x_df[col] = (pheno_x_df[col] - pheno_x_df[col].min()) / (pheno_x_df[col].max() - pheno_x_df[col].min())\n",
    "display(norm_pheno_x_df)\n",
    "\n",
    "norm_pheno_x = norm_pheno_x_df.to_numpy()\n",
    "print('----- Norm Pheno X Features -----')\n",
    "print(norm_pheno_x.shape)\n",
    "print(norm_pheno_x)\n",
    "np.save('./data/post_data/norm_pheno_x.npy', norm_pheno_x) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Formalize All x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfeature_dict_df = pd.read_csv('./data/filtered_data/subfeature_dict_df.csv')\n",
    "num_subfeature = subfeature_dict_df.shape[0]\n",
    "\n",
    "# unnormlized data\n",
    "geno_pheno_x = np.hstack((gene_x, pheno_x))\n",
    "dim_geno_pheno_x = geno_pheno_x.shape[1]\n",
    "subfeature_all_x = np.zeros((num_subfeature, dim_geno_pheno_x))\n",
    "all_x = np.vstack((subfeature_all_x, geno_pheno_x))\n",
    "print('----- ALL X Features -----')\n",
    "print(all_x.shape)\n",
    "# print(all_x)\n",
    "np.save('./data/post_data/all_x.npy', all_x)\n",
    "\n",
    "# normlized data\n",
    "norm_geno_pheno_x = np.hstack((norm_gene_x, norm_pheno_x))\n",
    "dim_norm_geno_pheno_x = norm_geno_pheno_x.shape[1]\n",
    "norm_subfeature_all_x = np.zeros((num_subfeature, dim_norm_geno_pheno_x))\n",
    "norm_all_x = np.vstack((norm_subfeature_all_x, norm_geno_pheno_x))\n",
    "print('----- Norm ALL X Features -----')\n",
    "print(norm_all_x.shape)\n",
    "# print(norm_all_x)\n",
    "np.save('./data/post_data/norm_all_x.npy', norm_all_x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "win_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
